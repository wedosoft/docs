---
sidebar_position: 5
---

# 인시던트 해결 및 복구

체계적인 해결 절차와 검증된 복구 방법을 통해 인시던트를 신속하고 안전하게 해결하여 서비스 정상화를 달성하는 핵심 프로세스입니다.

:::info 인시던트 해결 시작 전 필수 확인사항
- **백업 및 롤백 계획**: 해결 시도 전 현재 상태 백업 및 롤백 방안 사전 준비 필수
- **테스트 환경 검증**: 가능한 경우 테스트 환경에서 해결 방법 사전 검증 권장
- **변경 영향도 분석**: 해결 과정에서 발생할 수 있는 부수적 영향 사전 평가 필요
- **승인 및 권한**: 중요 시스템 변경 시 필요한 승인 절차 및 권한 사전 확보 필수
:::

## 해결 전략 및 방법론

### 단계별 해결 접근법

**1단계: 즉시 완화 조치 (Immediate Mitigation)**
- 서비스 영향 최소화를 위한 긴급 조치
- 사용자 접근 차단 또는 우회 경로 제공
- 추가 손상 방지를 위한 격리 조치

**2단계: 임시 해결 (Temporary Fix)**
- 서비스 복구를 위한 임시 방편 적용
- 제한된 기능으로라도 서비스 재개
- 근본 해결까지의 가교 역할

**3단계: 근본 해결 (Permanent Fix)**
- 인시던트 재발 방지를 위한 근본적 수정
- 시스템 설계 또는 프로세스 개선
- 장기적 안정성 확보

### 해결 방법 우선순위 결정

**위험도 기반 우선순위**:

| 위험도 | 해결 방법 | 적용 기준 | 승인 레벨 |
|--------|-----------|-----------|-----------|
| **낮음** | 표준 해결 절차 | 검증된 방법, 부작용 없음 | 팀장 승인 |
| **중간** | 제한적 변경 | 일부 기능 영향, 복구 가능 | 부서장 승인 |
| **높음** | 대규모 변경 | 시스템 전체 영향 | 경영진 승인 |
| **매우 높음** | 긴급 조치 | 서비스 완전 중단 위험 | 사후 보고 |

:::tip 효과적인 해결을 위한 모범사례
**점진적 적용 원칙**:
- 가장 안전한 방법부터 단계적 적용
- 각 단계마다 결과 검증 후 다음 단계 진행
- 실패 시 즉시 이전 상태로 롤백 가능하도록 준비
:::

## 서비스 복구 절차

### 복구 계획 수립

**복구 시나리오별 절차**:

```markdown
시나리오 A: 단일 서버 장애
1. 로드밸런서에서 장애 서버 제외
2. 정상 서버로 트래픽 재분산
3. 장애 서버 원인 분석 및 수정
4. 테스트 후 서비스 재투입

시나리오 B: 데이터베이스 장애
1. 읽기 전용 모드로 전환
2. 백업 데이터베이스로 페일오버
3. 주 데이터베이스 복구 작업
4. 데이터 동기화 후 정상 운영 전환

시나리오 C: 네트워크 장애
1. 우회 경로 활성화
2. DNS 설정 변경으로 트래픽 우회
3. 장애 경로 수리 및 테스트
4. 정상 경로로 트래픽 복원
```

### 복구 작업 실행

**표준 복구 절차**:

1. **사전 준비 (10분)**
   - 현재 상태 스냅샷 생성
   - 필요한 도구 및 권한 확인
   - 관련팀 및 이해관계자 대기 상태 확인

2. **복구 작업 실행 (시간 변동)**
   - 계획된 순서대로 복구 단계 수행
   - 각 단계별 체크포인트에서 상태 확인
   - 예상과 다른 결과 시 즉시 중단 및 재검토

3. **기능 검증 (15분)**
   - 핵심 기능 동작 테스트
   - 성능 지표 정상 범위 확인
   - 사용자 접근 및 작업 가능 여부 검증

4. **모니터링 강화 (지속)**
   - 복구 후 24시간 집중 모니터링
   - 이상 징후 조기 감지 체계 가동
   - 성능 지표 추이 지속 관찰

:::warning 복구 작업 시 주의사항
- **변경 통제**: 모든 변경사항은 반드시 문서화하여 추적 가능하도록 관리
- **롤백 준비**: 복구 실패 시 즉시 이전 상태로 되돌릴 수 있는 방안 항상 준비
- **커뮤니케이션**: 복구 진행 상황을 이해관계자에게 실시간 공유
:::

## 복구 검증 및 테스트

### 검증 체크리스트

**기능적 검증**:
```markdown
✅ 사용자 로그인 및 인증 기능
✅ 핵심 비즈니스 프로세스 동작
✅ 데이터 조회 및 수정 기능
✅ 외부 시스템과의 연동
✅ 백업 및 모니터링 시스템 연결
```

**성능 검증**:
```markdown
✅ 응답 시간 정상 범위 (< 3초)
✅ 처리량 기준치 달성 (분당 1000건)
✅ 리소스 사용률 안정 범위 (CPU < 70%)
✅ 동시 접속자 수 정상 처리
✅ 데이터베이스 쿼리 성능 정상
```

**안정성 검증**:
```markdown
✅ 30분간 연속 운영 안정성 확인
✅ 부하 증가 시나리오 테스트
✅ 장애 조건 재현 시 정상 동작 확인
✅ 예외 상황 처리 로직 동작 검증
```

### 자동화 테스트 도구

**헬스 체크 스크립트**:
```bash
#!/bin/bash
# 서비스 상태 종합 체크

echo "=== 서비스 상태 점검 시작 ==="

# 웹 서비스 응답 확인
if curl -f -s http://localhost:8080/health > /dev/null; then
    echo "✅ 웹 서비스 정상"
else
    echo "❌ 웹 서비스 응답 없음"
fi

# 데이터베이스 연결 확인
if mysql -u user -p password -e "SELECT 1" > /dev/null 2>&1; then
    echo "✅ 데이터베이스 연결 정상"
else
    echo "❌ 데이터베이스 연결 실패"
fi

# 로그 오류 확인
error_count=$(tail -n 100 /var/log/application.log | grep -i "error" | wc -l)
if [ $error_count -eq 0 ]; then
    echo "✅ 로그 오류 없음"
else
    echo "⚠️ 최근 로그에서 $error_count 개 오류 발견"
fi

echo "=== 점검 완료 ==="
```

## 서비스 정상화 확인

### 정상화 기준 정의

**서비스별 정상화 기준**:

| 서비스 유형 | 정상화 기준 | 측정 방법 | 확인 주기 |
|-------------|-------------|-----------|-----------|
| **웹 서비스** | 응답시간 < 3초, 가용성 > 99% | 모니터링 도구, 사용자 피드백 | 5분마다 |
| **데이터베이스** | 쿼리 응답 < 1초, 연결 수 정상 | DB 모니터링, 성능 카운터 | 1분마다 |
| **네트워크** | 패킷 손실 < 0.1%, 지연 < 100ms | 네트워크 모니터링 | 1분마다 |
| **배치 시스템** | 정시 실행, 처리량 기준 달성 | 스케줄러 로그, 처리 결과 | 작업 완료 시 |

### 사용자 영향 최소화 검증

**사용자 경험 관점 확인**:
1. **실제 사용자 테스트**
   - 다양한 사용자 그룹에서 기능 테스트 수행
   - 업무 시나리오별 정상 동작 확인
   - 모바일/데스크톱 환경별 확인

2. **비즈니스 프로세스 검증**
   - 주문-결제-배송 전체 플로우 테스트
   - 고객 서비스 프로세스 정상 동작 확인
   - 내부 업무 시스템 연동 검증

3. **데이터 무결성 확인**
   - 인시던트 기간 중 처리된 데이터 검증
   - 누락되거나 중복된 트랜잭션 확인
   - 필요시 데이터 복구 작업 수행

:::success 정상화 확인 효과
체계적인 검증을 통해 재발 방지 95% 달성, 사용자 만족도 회복 시간 80% 단축
:::

## 실무 활용 예시

### 상황 1: 웹서버 크래시로 인한 서비스 중단

**목표**: 웹서버 장애로 인한 서비스 중단을 최소 시간 내 복구

**해결 과정**:
1. **즉시 완화 조치 (5분)**
   - 로드밸런서에서 장애 서버 제외
   - 정상 서버로 모든 트래픽 리디렉션
   - 사용자에게 일시적 지연 안내

2. **임시 해결 (15분)**
   - 장애 서버 재시작 시도
   - 메모리 및 디스크 상태 점검
   - 기본 서비스 복구 확인

3. **근본 해결 (1시간)**
   - 크래시 덤프 분석으로 원인 파악
   - 메모리 누수 문제 수정 패치 적용
   - 모니터링 임계값 조정으로 조기 감지 체계 구축

**결과**: 서비스 중단 시간 20분, 사용자 영향 최소화, 재발 방지 완료

### 상황 2: 데이터베이스 손상으로 인한 데이터 접근 불가

**목표**: 데이터베이스 손상 복구 및 데이터 무결성 보장

**해결 과정**:
1. **즉시 완화 조치 (10분)**
   - 읽기 전용 복제본으로 조회 서비스 전환
   - 데이터 변경 기능 일시 중단
   - 백업 데이터베이스 상태 확인

2. **임시 해결 (30분)**
   - 최신 백업으로 임시 데이터베이스 구성
   - 제한된 기능으로 서비스 부분 재개
   - 손상 범위 및 복구 소요 시간 평가

3. **근본 해결 (2시간)**
   - 데이터베이스 무결성 검사 및 복구
   - 손상된 인덱스 재구성
   - 트랜잭션 로그 기반 데이터 일관성 복원

**결과**: 데이터 손실 0건, 서비스 완전 복구 2.5시간, 백업 정책 개선

### 상황 3: 네트워크 장비 장애로 인한 연결 불가

**목표**: 네트워크 장애로 인한 접속 불가 상황의 신속한 복구

**해결 과정**:
1. **즉시 완화 조치 (15분)**
   - 백업 네트워크 경로 활성화
   - DNS 설정 변경으로 트래픽 우회
   - 무선 네트워크 임시 확장으로 접속 경로 확보

2. **임시 해결 (45분)**
   - 장애 장비 바이패스 설정 구성
   - 임시 네트워크 구성으로 핵심 서비스 연결
   - 대역폭 제한 하에서 서비스 유지

3. **근본 해결 (4시간)**
   - 장애 네트워크 장비 교체
   - 네트워크 설정 복원 및 최적화
   - 이중화 구성 강화로 단일 장애점 제거

**결과**: 업무 중단 시간 1시간, 네트워크 이중화 완성, 복원력 향상

## 자동화 및 복구 도구

### 자동 복구 시스템

**자동 페일오버 설정**:
```yaml
# Kubernetes 자동 복구 설정 예시
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-service
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    spec:
      containers:
      - name: webapp
        image: webapp:latest
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

**자동 스케일링**:
- CPU 사용률 80% 초과 시 자동 확장
- 응답 시간 3초 초과 지속 시 인스턴스 추가
- 트래픽 감소 시 점진적 축소

### 복구 스크립트 자동화

**서비스 복구 자동화 스크립트**:
```bash
#!/bin/bash
# 서비스 자동 복구 스크립트

SERVICE_NAME="web-service"
HEALTH_URL="http://localhost:8080/health"
MAX_RETRIES=3

echo "서비스 복구 스크립트 시작: $SERVICE_NAME"

for i in $(seq 1 $MAX_RETRIES); do
    echo "복구 시도 $i/$MAX_RETRIES"
    
    # 서비스 재시작
    systemctl restart $SERVICE_NAME
    sleep 10
    
    # 헬스 체크
    if curl -f -s $HEALTH_URL > /dev/null; then
        echo "✅ 서비스 복구 성공"
        exit 0
    else
        echo "❌ 복구 실패, 재시도..."
    fi
done

echo "🚨 자동 복구 실패 - 수동 개입 필요"
# 알림 발송
curl -X POST "https://alerts.company.com/webhook" \
     -d "{'service': '$SERVICE_NAME', 'status': 'auto-recovery-failed'}"
exit 1
```

## 성과 측정 및 개선

### 복구 성능 지표

| 지표명 | 목표 수치 | 측정 방법 | 현재 달성도 |
|--------|-----------|-----------|-------------|
| **평균 복구 시간 (MTTR)** | < 2시간 | 인시던트 시작 ~ 완전 복구 | 1.8시간 |
| **복구 성공률** | > 95% | 성공적 복구 / 전체 시도 | 94% |
| **재발 방지 효과** | < 5% | 동일 원인 재발 비율 | 6% |
| **사용자 영향 최소화** | > 80% | 영향 감소율 | 78% |

### 지속적 개선 활동

**복구 프로세스 최적화**:
1. **복구 시간 단축**
   - 자주 사용되는 복구 절차 자동화
   - 사전 준비된 복구 스크립트 활용
   - 병렬 처리 가능한 작업 최적화

2. **복구 성공률 향상**
   - 검증된 복구 절차 표준화
   - 리스크 평가 기준 개선
   - 팀원 교육 및 훈련 강화

## 문제 해결 가이드

### 자주 발생하는 복구 중 문제들

#### 문제: 복구 과정에서 추가 문제 발생

**원인**: 복구 절차의 부작용 미예측 또는 시스템 의존성 파악 부족

**해결**:
1. **즉시 롤백 실행**
   - 복구 시도 전 상태로 즉시 되돌리기
   - 추가 손상 방지를 위한 서비스 격리
   - 원인 분석을 위한 상태 정보 수집

2. **복구 계획 재검토**
   - 시스템 의존성 재분석
   - 부작용 가능성 상세 평가
   - 더 안전한 복구 방법 선택

#### 문제: 복구 후 성능 저하 지속

**원인**: 근본 원인 미해결 또는 복구 과정에서 성능 최적화 누락

**해결**:
1. **성능 분석 수행**
   - 복구 전후 성능 지표 비교
   - 병목 구간 재식별
   - 추가 최적화 필요 영역 파악

2. **단계적 성능 개선**
   - 우선순위 기반 개선 작업 수행
   - 각 개선 후 효과 측정
   - 안정성 확보 후 다음 단계 진행

:::warning 복구 작업 시 주의사항
- **검증 철저**: 각 복구 단계마다 반드시 기능 및 성능 검증 수행
- **문서화 지속**: 모든 복구 과정과 결과를 상세히 기록하여 향후 참고 자료로 활용
- **학습 반영**: 복구 과정에서 얻은 교훈을 프로세스 개선에 즉시 반영
:::

## 관련 기능 및 연계

인시던트 해결 및 복구와 연계되는 핵심 프로세스들:

- **[인시던트 조사 및 진단](./incident-investigation-diagnosis/)**: 해결 방안 도출을 위한 정확한 원인 분석
- **[인시던트 종료 및 검토](./incident-closure-review/)**: 복구 완료 후 공식적 종료 및 개선점 도출
- **[인시던트 커뮤니케이션](./incident-communication-updates/)**: 복구 진행 상황의 이해관계자 공유
- **[인시던트 지표 및 SLA 보고](./incident-metrics-sla-reporting/)**: 복구 성과 측정 및 SLA 영향 분석