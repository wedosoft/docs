#!/usr/bin/env python3
"""
ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°
ê¸°ì¤€: ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ë¬¸ì„œ VS ë‚˜ë¨¸ì§€ ëª¨ë“  ë¬¸ì„œ
"""

import pandas as pd
import re
import json
from pathlib import Path

def is_pure_text(html_content):
    """
    ìˆœìˆ˜ í…ìŠ¤íŠ¸ì¸ì§€ íŒë‹¨ (ê°„ë‹¨í•œ ê¸°ì¤€)
    - ë³µì¡ ë¬¸ì„œ: ì´ë¯¸ì§€, í…Œì´ë¸”, ë¦¬ìŠ¤íŠ¸, ì½”ë“œë¸”ë¡ ë“±ì´ ìˆëŠ” ë¬¸ì„œ
    - ë‹¨ìˆœ ë¬¸ì„œ: ìœ„ ìš”ì†Œë“¤ì´ ì—†ëŠ” ë‚˜ë¨¸ì§€ ëª¨ë“  ë¬¸ì„œ
    """
    if pd.isna(html_content) or html_content == '':
        return True  # ë¹ˆ ë‚´ìš©ì€ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼
    
    html_str = str(html_content)
    
    # ë³µì¡í•œ ìš”ì†Œë“¤ (ì´ê²ƒë“¤ì´ ìˆìœ¼ë©´ ë³µì¡ ë¬¸ì„œ)
    complex_elements = [
        '<img',           # ì´ë¯¸ì§€
        '<table',         # í…Œì´ë¸”
        '<tr>',           # í…Œì´ë¸” í–‰
        '<th>',           # í…Œì´ë¸” í—¤ë”  
        '<td>',           # í…Œì´ë¸” ì…€
        '<ul>',           # ìˆœì„œì—†ëŠ” ë¦¬ìŠ¤íŠ¸
        '<ol>',           # ìˆœì„œìˆëŠ” ë¦¬ìŠ¤íŠ¸
        '<li>',           # ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ
        '<pre>',          # ì½”ë“œ ë¸”ë¡
        '<code>',         # ì¸ë¼ì¸ ì½”ë“œ
        '<iframe',        # í”„ë ˆì„
        '<video',         # ë¹„ë””ì˜¤
        '<audio',         # ì˜¤ë””ì˜¤
        'style=',         # ì¸ë¼ì¸ ìŠ¤íƒ€ì¼
        '<script',        # ìŠ¤í¬ë¦½íŠ¸
        '<form',          # í¼
        '<input',         # ì…ë ¥ í•„ë“œ
        '<select',        # ì„ íƒ ë°•ìŠ¤
        '<textarea',      # í…ìŠ¤íŠ¸ ì˜ì—­
    ]
    
    # í•˜ë‚˜ë¼ë„ ë³µì¡í•œ ìš”ì†Œê°€ ìˆìœ¼ë©´ ë³µì¡ ë¬¸ì„œ
    for element in complex_elements:
        if element in html_str:
            return False
    
    return True  # ë³µí•© ìš”ì†Œê°€ ì—†ìœ¼ë©´ ìˆœìˆ˜ í…ìŠ¤íŠ¸

def analyze_faq_documents():
    """FAQ ë¬¸ì„œë§Œ ë¶„ì„í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ì™€ ë³µí•© ë¬¸ì„œë¡œ ë¶„ë¥˜"""
    
    # CSV íŒŒì¼ë“¤ ì½ê¸°
    csv_files = [
        'raw_data/merged_articles_links_replaced_freshservice_part1.csv',
        'raw_data/merged_articles_links_replaced_freshservice_part2.csv', 
        'raw_data/merged_articles_links_replaced_freshservice_part3.csv',
        'raw_data/merged_articles_links_replaced_freshservice_part4.csv',
        'raw_data/merged_articles_links_replaced_freshservice_part5.csv'
    ]
    
    pure_text_docs = []
    complex_docs = []
    
    for csv_file in csv_files:
        try:
            df = pd.read_csv(csv_file)
            print(f"ë¶„ì„ ì¤‘: {csv_file} ({len(df)}ê°œ í•­ëª©)")
            
            for idx, row in df.iterrows():
                title = str(row.get('title', ''))
                description = str(row.get('description', ''))
                html_content = str(row.get('description', ''))
                path = str(row.get('path', ''))
                
                # FAQ ë¬¸ì„œë§Œ í•„í„°ë§
                if 'faq' not in path.lower():
                    continue
                
                doc_info = {
                    'title': title,
                    'path': path,
                    'content_length': len(html_content),
                    'csv_file': csv_file,
                    'row_index': idx
                }
                
                if is_pure_text(html_content):
                    pure_text_docs.append(doc_info)
                else:
                    complex_docs.append(doc_info)
        
        except FileNotFoundError:
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ ({csv_file}): {e}")
    
    # ê²°ê³¼ ìš”ì•½
    total_docs = len(pure_text_docs) + len(complex_docs)
    pure_text_ratio = len(pure_text_docs) / total_docs * 100 if total_docs > 0 else 0
    
    print("\n" + "="*50)
    print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    print("="*50)
    print(f"ì „ì²´ ë¬¸ì„œ: {total_docs:,}ê°œ")
    print(f"ìˆœìˆ˜ í…ìŠ¤íŠ¸: {len(pure_text_docs):,}ê°œ ({pure_text_ratio:.1f}%)")
    print(f"ë³µí•© ë¬¸ì„œ: {len(complex_docs):,}ê°œ ({100-pure_text_ratio:.1f}%)")
    print()
    
    print("ğŸ¤– ìë™ë²ˆì—­ ê¶Œì¥:")
    print(f"  - ìˆœìˆ˜ í…ìŠ¤íŠ¸ {len(pure_text_docs):,}ê°œ â†’ ì¦‰ì‹œ ìë™ë²ˆì—­ ê°€ëŠ¥")
    print(f"  - ë³µí•© ë¬¸ì„œ {len(complex_docs):,}ê°œ â†’ ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”")
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    results = {
        'summary': {
            'total_docs': total_docs,
            'pure_text_count': len(pure_text_docs),
            'complex_count': len(complex_docs),
            'pure_text_ratio': pure_text_ratio
        },
        'pure_text_docs': pure_text_docs,
        'complex_docs': complex_docs
    }
    
    with open('simple_text_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nê²°ê³¼ê°€ 'simple_text_analysis.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒ˜í”Œ ë³´ê¸°
    if pure_text_docs:
        print("\n" + "="*50)
        print("ğŸ“ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ)")
        print("="*50)
        for i, doc in enumerate(pure_text_docs[:5]):
            print(f"{i+1}. {doc['title']}")
            print(f"   ê²½ë¡œ: {doc['path']}")
            print(f"   ê¸¸ì´: {doc['content_length']}ì")
            print()
    
    # ë³µí•© ë¬¸ì„œ ìƒ˜í”Œ ë³´ê¸°
    if complex_docs:
        print("\n" + "="*50)
        print("ğŸ”§ ë³µí•© ë¬¸ì„œ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ)")
        print("="*50)
        for i, doc in enumerate(complex_docs[:5]):
            print(f"{i+1}. {doc['title']}")
            print(f"   ê²½ë¡œ: {doc['path']}")
            print(f"   ê¸¸ì´: {doc['content_length']}ì")
            print()

if __name__ == "__main__":
    analyze_faq_documents()
