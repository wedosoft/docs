#!/usr/bin/env python3
"""
FAQ ì „ìš© ë³µì¡ë„ ë¶„ì„ê¸°
Freshservice FAQs ì¹´í…Œê³ ë¦¬ë§Œ ë¶„ì„í•˜ì—¬ íš¨ìœ¨ì ì¸ ì‘ì—… ê³„íš ìˆ˜ë¦½
"""

import pandas as pd
import re
import json
from pathlib import Path
import html

def analyze_content_complexity(html_content):
    """HTML ì½˜í…ì¸ ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„"""
    if pd.isna(html_content):
        return {
            'complexity_score': 0,
            'has_images': False,
            'has_tables': False,
            'has_code_blocks': False,
            'has_lists': False,
            'has_formatting': False,
            'image_count': 0,
            'content_length': 0,
            'processing_recommendation': 'AUTO'
        }
    
    html_str = str(html_content)
    content_length = len(html_str)
    complexity_score = 0
    
    # ì´ë¯¸ì§€ ë¶„ì„
    image_count = html_str.count('<img')
    has_images = image_count > 0
    if has_images:
        complexity_score += 5 * image_count  # ì´ë¯¸ì§€ë§ˆë‹¤ 5ì 
    
    # í…Œì´ë¸” ë¶„ì„
    has_tables = '<table' in html_str or '<th>' in html_str or '<td>' in html_str
    if has_tables:
        table_count = html_str.count('<table')
        complexity_score += 3 * table_count  # í…Œì´ë¸”ë§ˆë‹¤ 3ì 
    
    # ì½”ë“œ ë¸”ë¡ ë¶„ì„
    has_code_blocks = '<pre>' in html_str or '<code>' in html_str
    if has_code_blocks:
        code_count = html_str.count('<pre>') + html_str.count('<code>')
        complexity_score += 2 * code_count  # ì½”ë“œ ë¸”ë¡ë§ˆë‹¤ 2ì 
    
    # ë¦¬ìŠ¤íŠ¸ ë¶„ì„
    has_lists = '<ul>' in html_str or '<ol>' in html_str
    if has_lists:
        list_count = html_str.count('<ul>') + html_str.count('<ol>')
        complexity_score += 1 * list_count  # ë¦¬ìŠ¤íŠ¸ë§ˆë‹¤ 1ì 
    
    # ì„œì‹ ë¶„ì„ (êµµê²Œ, ê¸°ìš¸ì„, ì œëª© ë“±)
    formatting_patterns = ['<strong>', '<b>', '<em>', '<i>', '<h1>', '<h2>', '<h3>', '<h4>', '<h5>', '<h6>']
    has_formatting = any(pattern in html_str for pattern in formatting_patterns)
    if has_formatting:
        formatting_count = sum(html_str.count(pattern) for pattern in formatting_patterns)
        complexity_score += 0.5 * formatting_count  # ì„œì‹ë§ˆë‹¤ 0.5ì 
    
    # ì „ì²´ ê¸¸ì´ ë³´ë„ˆìŠ¤
    if content_length > 2000:
        complexity_score += 2
    elif content_length > 1000:
        complexity_score += 1
    
    # ì²˜ë¦¬ ë°©ë²• ê²°ì •
    if complexity_score >= 10:
        processing_recommendation = 'MANUAL'  # ìˆ˜ë™ ì²˜ë¦¬
    elif complexity_score >= 5:
        processing_recommendation = 'REVIEW'  # ê²€í†  í•„ìš”
    else:
        processing_recommendation = 'AUTO'    # ìë™ ì²˜ë¦¬
    
    return {
        'complexity_score': complexity_score,
        'has_images': has_images,
        'has_tables': has_tables,
        'has_code_blocks': has_code_blocks,
        'has_lists': has_lists,
        'has_formatting': has_formatting,
        'image_count': image_count,
        'content_length': content_length,
        'processing_recommendation': processing_recommendation
    }

def analyze_faq_only():
    """FAQ ì¹´í…Œê³ ë¦¬ë§Œ ë¶„ì„í•˜ì—¬ ë³µì¡ë„ë³„ë¡œ ë¶„ë¥˜"""
    
    # CSV íŒŒì¼ë“¤ ì½ê¸°
    csv_files = [
        'raw_data/merged_articles_links_replaced_freshservice_part1.csv',
        'raw_data/merged_articles_links_replaced_freshservice_part2.csv', 
        'raw_data/merged_articles_links_replaced_freshservice_part3.csv',
        'raw_data/merged_articles_links_replaced_freshservice_part4.csv',
        'raw_data/merged_articles_links_replaced_freshservice_part5.csv'
    ]
    
    all_results = []
    
    for csv_file in csv_files:
        try:
            df = pd.read_csv(csv_file)
            # FAQ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
            faq_df = df[df['category_name'] == 'Freshservice FAQs']
            
            if len(faq_df) == 0:
                print(f"ì²˜ë¦¬ ì¤‘: {csv_file} (FAQ ë¬¸ì„œ ì—†ìŒ)")
                continue
                
            print(f"ì²˜ë¦¬ ì¤‘: {csv_file} (FAQ ë¬¸ì„œ {len(faq_df)}ê°œ)")
            
            for idx, row in faq_df.iterrows():
                title = str(row.get('title', ''))
                description = str(row.get('description', ''))
                html_content = str(row.get('description', ''))  # ì‹¤ì œ HTMLì€ description ì»¬ëŸ¼ì— ìˆìŒ
                folder_name = str(row.get('folder_name', ''))
                
                # ë³µì¡ë„ ë¶„ì„
                complexity = analyze_content_complexity(html_content)
                
                result = {
                    'title': title,
                    'folder_name': folder_name,
                    'description_preview': description[:100] + '...' if len(description) > 100 else description,
                    **complexity
                }
                
                all_results.append(result)
                
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ {csv_file}: {e}")
    
    return all_results

def generate_faq_summary_report(results):
    """FAQ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    # í´ë”ë³„ ë¶„ë¥˜
    by_folder = {}
    for result in results:
        folder = result['folder_name']
        if folder not in by_folder:
            by_folder[folder] = []
        by_folder[folder].append(result)
    
    # ì²˜ë¦¬ ë°©ë²•ë³„ ë¶„ë¥˜
    manual_count = len([r for r in results if r['processing_recommendation'] == 'MANUAL'])
    review_count = len([r for r in results if r['processing_recommendation'] == 'REVIEW'])
    auto_count = len([r for r in results if r['processing_recommendation'] == 'AUTO'])
    
    print("=" * 60)
    print("ğŸ“Š FAQ ì „ìš© ë³µì¡ë„ ë¶„ì„ ê²°ê³¼")
    print("=" * 60)
    print(f"ì´ FAQ ìˆ˜: {len(results)}")
    print(f"ğŸ”¥ ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”: {manual_count}ê°œ ({manual_count/len(results)*100:.1f}%)")
    print(f"âš¡ ê²€í†  í•„ìš”: {review_count}ê°œ ({review_count/len(results)*100:.1f}%)")
    print(f"ğŸ¤– ìë™ ì²˜ë¦¬ ê°€ëŠ¥: {auto_count}ê°œ ({auto_count/len(results)*100:.1f}%)")
    print()
    
    # í´ë”ë³„ ìƒì„¸ ë¶„ì„ (ìë™ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìˆœì„œëŒ€ë¡œ)
    print("ğŸ“‹ í´ë”ë³„ ë¶„ì„ (ìë™ ì²˜ë¦¬ ê°€ëŠ¥ ë¬¸ì„œ ë§ì€ ìˆœ):")
    print("-" * 60)
    
    folder_stats = []
    for folder, items in by_folder.items():
        manual = len([i for i in items if i['processing_recommendation'] == 'MANUAL'])
        review = len([i for i in items if i['processing_recommendation'] == 'REVIEW'])
        auto = len([i for i in items if i['processing_recommendation'] == 'AUTO'])
        
        folder_stats.append({
            'folder': folder,
            'total': len(items),
            'auto': auto,
            'review': review,
            'manual': manual,
            'auto_ratio': auto / len(items) * 100
        })
    
    # ìë™ ì²˜ë¦¬ ê°€ëŠ¥ ë¹„ìœ¨ ìˆœìœ¼ë¡œ ì •ë ¬
    folder_stats.sort(key=lambda x: x['auto_ratio'], reverse=True)
    
    for stat in folder_stats:
        print(f"{stat['folder'][:35]:35} | ìë™:{stat['auto']:2}ê°œ ê²€í† :{stat['review']:2}ê°œ ìˆ˜ë™:{stat['manual']:2}ê°œ | ì´:{stat['total']:2}ê°œ ({stat['auto_ratio']:4.1f}% ìë™)")
    
    print()
    
    # ìˆ˜ë™ ì²˜ë¦¬ê°€ í•„ìš”í•œ í•­ëª©ë“¤ ìƒì„¸ ì •ë³´
    manual_items = [r for r in results if r['processing_recommendation'] == 'MANUAL']
    if manual_items:
        print("ğŸ”¥ ìˆ˜ë™ ì²˜ë¦¬ í•„ìš” í•­ëª©ë“¤ (ìƒìœ„ 10ê°œ):")
        print("-" * 60)
        
        for item in sorted(manual_items, key=lambda x: x['complexity_score'], reverse=True)[:10]:
            features = []
            if item['has_images']:
                features.append(f"ì´ë¯¸ì§€ {item['image_count']}ê°œ")
            if item['has_tables']:
                features.append("í…Œì´ë¸”")
            if item['has_lists']:
                features.append("ëª©ë¡")
            
            feature_text = ", ".join(features) if features else "ê¸´ ë¬¸ì„œ"
            print(f"- [{item['folder_name']}] {item['title'][:40]}...")
            print(f"  ì ìˆ˜: {item['complexity_score']}, íŠ¹ì§•: {feature_text}")
    
    return {
        'total': len(results),
        'manual': manual_count,
        'review': review_count,
        'auto': auto_count,
        'folder_stats': folder_stats
    }

def save_faq_results(results, output_file='faq_only_analysis.json'):
    """ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    print("ğŸ” FAQ ì „ìš© ë³µì¡ë„ ë¶„ì„ ì‹œì‘...")
    
    # FAQë§Œ ë¶„ì„ ì‹¤í–‰
    results = analyze_faq_only()
    
    if not results:
        print("âŒ FAQ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    summary = generate_faq_summary_report(results)
    
    # ìƒì„¸ ê²°ê³¼ ì €ì¥
    save_faq_results(results)
    
    print("\nâœ… FAQ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š ìš”ì•½: ìˆ˜ë™ {summary['manual']}ê°œ, ê²€í†  {summary['review']}ê°œ, ìë™ {summary['auto']}ê°œ")
